Q：用cursor、lingma都出不来特别好的视觉效果，这是为何啊
你可以给你一个大屏的参考截屏，然后告诉它这种样式

Q：请问这节课的目标是什么？embedding和向量数据库后续我们会怎么用呢？
用于RAG知识库

Q：老师，向量数据库和rag之间有什么关联？
向量数据库 => 保存了embedding向量，通过数学计算，判断 query向量 和 哪个片段向量更接近 => 用于筛选 Top5的片段 => 放到 LLM上下文中，进行RAG

Embedding模型，LLM模型 这是两个模型

Q：llm 也可以做语义理解，和embedding的区别是什么呢
成本 deepseek-r1 671B

Q：假如我现在有很多专业性资料，我如何从零开始训练出自己的embedding模型？并且打包成网上那种能下载的模型？
word2vec 可以训练
BERT 训练你的语料

Q：分词后是1024维，对吗
原始句子 => 分词后，得到 [a b c d] =>压缩到一个空间中 embedding

Q: 我们在做推荐系统时，还需要llm吗？如果需要，那么他应该是用于干嘛？
DeepFM, NFM, Wide & Deep (神经网络模型） 
专门学习你的数据，创建的专有模型

pip install faiss-cpu
pip install faiss-gpu

Q: 有了向量为什么还要元数据？能不能再举例讲解
向量是用于相似度计算 => 筛选片段的依据
元数据，可以保存原始的文本，用于放到 LLM中

CLIP，Dinov2




