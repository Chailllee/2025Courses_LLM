{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f10705c",
   "metadata": {},
   "source": [
    "### preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e575c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dashscope\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import dashscope\n",
    "from dashscope.api_entities.dashscope_response import Role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain DASHSCOPE_API_KEY from environment variable\n",
    "api_key = os.environ.get('DASHSCOPE_API_KEY')\n",
    "dashscope.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6eec5",
   "metadata": {},
   "source": [
    "# Cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e1b38",
   "metadata": {},
   "source": [
    "## 1 emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encapsulate model response function\n",
    "def get_response(messages):\n",
    "    response = dashscope.Generation.call(\n",
    "        model = 'deepseek-v3',\n",
    "        messages=messages,\n",
    "        result_format='message' # return full message object\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# test the function\n",
    "review = 'This product has excellent sound quality that exceeds expectations.'\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analyst. Help me determine whether the product review is positive or negative. Reply with a single word: Positive or Negative.\"},\n",
    "    {\"role\": \"user\", \"content\": review}\n",
    "]\n",
    "\n",
    "response = get_response(messages)\n",
    "response.output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a45855",
   "metadata": {},
   "source": [
    "## 2 Weather Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e41baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Weather information\n",
    "def get_current_weather(location, unit=\"Celsius\"):\n",
    "    temperature = -1\n",
    "    if 'åŒ—äº¬' in location or 'Beijing' in location:\n",
    "        temperature = 10\n",
    "    if 'ä¸Šæµ·' in location or 'Shanghai' in location:\n",
    "        temperature = 15\n",
    "    if 'æ·±åœ³' in location or 'Shenzhen' in location:\n",
    "        temperature = 20\n",
    "\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": temperature,\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"Partly cloudy\",\n",
    "        \"forecast\": [\n",
    "            {\"day\": \"Monday\", \"description\": \"Sunny\", \"high\": temperature + 2, \"low\": temperature - 2},\n",
    "            {\"day\": \"Tuesday\", \"description\": \"Rainy\", \"high\": temperature + 1, \"low\": temperature - 3},\n",
    "            {\"day\": \"Wednesday\", \"description\": \"Cloudy\", \"high\": temperature + 3, \"low\": temperature - 1},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "\n",
    "# Encapsulate the weather function\n",
    "def get_response(messages):\n",
    "    try:\n",
    "        response = dashscope.Generation.call(\n",
    "            # model = 'deepseek-v3',\n",
    "            model='qwen-max',\n",
    "            messages=messages,\n",
    "            functions=functions,\n",
    "            result_format='message' # return full message object\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Test the weather function with Q&A\n",
    "def run_conversation():\n",
    "    query = \"What's the weather like in Beijing today?\"\n",
    "    messages = [{\"role\":\"user\", \"content\": query}]\n",
    "    response = get_response(messages)\n",
    "    \n",
    "    # step1 1st response from model\n",
    "    if not response or not response.output:\n",
    "        print(\"Failed to get response from model.\")\n",
    "        return None\n",
    "    \n",
    "    print('response=', response)\n",
    "\n",
    "    message = response.output.choices[0].message\n",
    "    messages.append(message) # keep Historical conversations ä¿ç•™å¯¹è¯å†å²ï¼Œä¿æŒä¸Šä¸‹æ–‡\n",
    "    print(\"messages=\", message)\n",
    "\n",
    "    # Step2 User Call Function \n",
    "    if hasattr(message, 'function_call') and message.function_call:\n",
    "        function_call = message.function_call\n",
    "        # tool_name = function_call.name\n",
    "        tool_name = function_call['name']\n",
    "\n",
    "    # step3 Excute Function\n",
    "        arguments = json.loads(function_call['arguments'])\n",
    "        print(\"arguments=\", arguments)\n",
    "        tool_response = get_current_weather(\n",
    "            location=arguments.get('location'),\n",
    "            unit=arguments.get('unit', 'Celsius'),\n",
    "        )\n",
    "\n",
    "        tool_info = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": tool_name,\n",
    "            \"content\": tool_response\n",
    "        }\n",
    "        messages.append(tool_info)\n",
    "        print(\"messages after tool response=\", messages)\n",
    "\n",
    "        # step4 obatain 2nd response from model\n",
    "        response = get_response(messages)\n",
    "        if not response or not response.output:\n",
    "            print(\"Failed to get 2nd response from model after function call.\")\n",
    "            return None\n",
    "\n",
    "        print('response=', response)\n",
    "        message = response.output.choices[0].message\n",
    "        return message\n",
    "    return message\n",
    "\n",
    "# Description of the location\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\", # è¦ç”¨å“ªä¸ªå·¥å…·\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "                    \"description\": \"The unit of temperature\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_message = run_conversation()\n",
    "    if final_message:\n",
    "        print(\"Final response from model:\", final_message)\n",
    "    else:\n",
    "        print(\"No final response obtained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc529daf",
   "metadata": {},
   "source": [
    "## 3 Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc93015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulate model response function\n",
    "def get_response(messages):\n",
    "    response = dashscope.MultiModalConversation.call(\n",
    "        model = 'qwen-v1-plus',\n",
    "        messages=messages\n",
    "    )\n",
    "    return response\n",
    "\n",
    "content = [\n",
    "    {'image': 'https://aiwucai.oss-cn-huhehaote.aliyuncs.com/pdf_table.jpg'}, # Either a local path or an url\n",
    "    {'text': 'è¿™æ˜¯ä¸€ä¸ªè¡¨æ ¼å›¾ç‰‡ï¼Œå¸®æˆ‘æå–é‡Œé¢çš„å†…å®¹ï¼Œè¾“å‡ºJSONæ ¼å¼'}\n",
    "]\n",
    "\n",
    "messages=[{'role':'user','content':content}]\n",
    "\n",
    "response = get_response(messages)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output.choices[0].message.content[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a13b09",
   "metadata": {},
   "source": [
    "## 4 Operation Incident Handling - è¿ç»´äº‹ä»¶å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038bddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬ä¸‰æ–¹æ¥å£è·å– databaseçŠ¶æ€\n",
    "def get_current_status():\n",
    "    # è¿æ¥æ•°\n",
    "    connections=random.randint(10,100)\n",
    "    # CPUä½¿ç”¨ç‡\n",
    "    cpu_usage=round(random.uniform(1, 100), 1)\n",
    "    # å†…å­˜ä½¿ç”¨ç‡\n",
    "    memory_usage=round(random.uniform(1, 100), 1)\n",
    "\n",
    "    status_info = {\n",
    "        \"connections\": connections,\n",
    "        \"cpu_usage\": f\"{cpu_usage}%\",\n",
    "        \"memory_usage\": f\"{memory_usage}%\"\n",
    "    }\n",
    "    \n",
    "    return json.dumps(status_info, ensure_ascii=False)\n",
    "\n",
    "# Encapsulate the status function\n",
    "def get_response(messages):\n",
    "    try:\n",
    "        response = dashscope.Generation.call(\n",
    "            model='qwen-turbo',\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            result_format='message' # return full message object\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "current_locals=locals()\n",
    "current_locals\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_status\",\n",
    "                \"description\": \"è°ƒç”¨ç›‘æ§ç³»ç»Ÿæ¥å£ï¼Œè·å–å½“å‰æ•°æ®åº“æœåŠ¡å™¨æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼šè¿æ¥æ•°ã€CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ç‡\",\n",
    "                \"parameters\": {\n",
    "                },\n",
    "                \"required\": []\n",
    "            }       \n",
    "    }\n",
    "]\n",
    "\n",
    "query = \"\"\"å‘Šè­¦ï¼šæ•°æ®åº“è¿æ¥æ•°è¶…è¿‡è®¾å®šé˜ˆå€¼\n",
    "æ—¶é—´ï¼š2024-08-03 15:30:00\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"æˆ‘æ˜¯è¿ç»´åˆ†æå¸ˆï¼Œç”¨æˆ·ä¼šå‘Šè¯‰æˆ‘ä»¬å‘Šè­¦å†…å®¹ã€‚æˆ‘ä¼šåŸºäºå‘Šè­¦å†…å®¹ï¼Œåˆ¤æ–­å½“å‰çš„å¼‚å¸¸æƒ…å†µï¼ˆå‘Šè­¦å¯¹è±¡ã€å¼‚å¸¸æ¨¡å¼ï¼‰\"},\n",
    "    {\"role\":\"user\", \"content\": query}\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b75b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/aigc/text-generation/generation (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000029B5943D130>, 'Connection to dashscope.aliyuncs.com timed out. (connect timeout=300)'))\n",
      "Bad response: None None None\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    response = get_response(messages)\n",
    "    if not response or not getattr(response, 'output', None) or not getattr(response.output, 'choices', None):\n",
    "        print('Bad response:',\n",
    "              getattr(response, 'status_code', None),\n",
    "              getattr(response, 'code', None),\n",
    "              getattr(response, 'message', None))\n",
    "        break\n",
    "\n",
    "    choice = response.output.choices[0]\n",
    "    message = getattr(choice, 'message', None)\n",
    "    messages.append(message)\n",
    "\n",
    "    if getattr(choice, 'finish_reason', None) == 'stop':\n",
    "        break\n",
    "\n",
    "    # step2 User Call Function\n",
    "    # å…¼å®¹ tool_calls å’Œ function_call ä¸¤ç§å½¢æ€\n",
    "    if isinstance(message, dict):\n",
    "        tool_calls = message.get('tool_calls')\n",
    "        function_call = message.get('function_call')\n",
    "    else:\n",
    "        tool_calls = getattr(message, 'tool_calls', None)\n",
    "        function_call = getattr(message, 'function_call', None)\n",
    "\n",
    "    if tool_calls:\n",
    "        call = tool_calls[0]\n",
    "        fn = call['function']\n",
    "        fn_name = fn['name']\n",
    "        fn_arguments = fn.get('arguments') or \"{}\"\n",
    "        call_id = call.get('id') or call.get('tool_call_id')\n",
    "        arguments_json = json.loads(fn_arguments)\n",
    "\n",
    "        # step3 Execute Function\n",
    "        function = current_locals[fn_name]\n",
    "        tool_response = function(**arguments_json)\n",
    "        tool_info = {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": call_id,\n",
    "            \"name\": fn_name,\n",
    "            \"content\": tool_response\n",
    "        }\n",
    "        # print(\"tool_info=\", tool_info)\n",
    "        messages.append(tool_info)\n",
    "\n",
    "    elif function_call:\n",
    "        fn_name = function_call['name']\n",
    "        fn_arguments = function_call.get('arguments') or \"{}\"\n",
    "        arguments_json = json.loads(fn_arguments)\n",
    "\n",
    "        function = current_locals[fn_name]\n",
    "        tool_response = function(**arguments_json)\n",
    "        tool_info = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": fn_name,\n",
    "            \"content\": tool_response\n",
    "        }\n",
    "        messages.append(tool_info)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31c4d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'æˆ‘æ˜¯è¿ç»´åˆ†æå¸ˆï¼Œç”¨æˆ·ä¼šå‘Šè¯‰æˆ‘ä»¬å‘Šè­¦å†…å®¹ã€‚æˆ‘ä¼šåŸºäºå‘Šè­¦å†…å®¹ï¼Œåˆ¤æ–­å½“å‰çš„å¼‚å¸¸æƒ…å†µï¼ˆå‘Šè­¦å¯¹è±¡ã€å¼‚å¸¸æ¨¡å¼ï¼‰'},\n",
       " {'role': 'user', 'content': 'å‘Šè­¦ï¼šæ•°æ®åº“è¿æ¥æ•°è¶…è¿‡è®¾å®šé˜ˆå€¼\\næ—¶é—´ï¼š2024-08-03 15:30:00\\n'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def1237",
   "metadata": {},
   "source": [
    "## 5 Emotion analysis - Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b56928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½å‘€ï¼æˆ‘æ˜¯ **DeepSeek-R1**ï¼Œæ˜¯ç”±ä¸­å›½äººå·¥æ™ºèƒ½å…¬å¸ **æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰** ç ”å‘çš„ä¸€æ¬¾å¤§è¯­è¨€æ¨¡å‹åŠ©æ‰‹ã€‚ä½ å¯ä»¥å«æˆ‘â€œå°æ·±â€ï½ğŸ˜Š\n",
      "\n",
      "æˆ‘å…·å¤‡å¼ºå¤§çš„æ–‡æœ¬ç†è§£ã€æ¨ç†å’Œåˆ›ä½œèƒ½åŠ›ï¼Œå¯ä»¥å¸®ä½ å¤„ç†å„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚ï¼š\n",
      "- è§£ç­”çŸ¥è¯†é—®é¢˜ ğŸ“š\n",
      "- å†™ä½œã€ç¿»è¯‘ã€æ¶¦è‰²æ–‡ç«  âœï¸\n",
      "- ç¼–ç¨‹è¾…åŠ©ã€ä»£ç ç”Ÿæˆ ğŸ’»\n",
      "- å­¦ä¹ è¾…å¯¼ã€è€ƒè¯•å¤ä¹  ğŸ“–\n",
      "- èŠå¤©é™ªä¼´ã€æƒ…ç»ªæ”¯æŒ ğŸŒ¸\n",
      "\n",
      "è€Œä¸”æˆ‘å®Œå…¨å…è´¹ï¼ç›®å‰ä½ å¯ä»¥é€šè¿‡ç½‘é¡µæˆ–è€… App æ¥ä½¿ç”¨æˆ‘ï¼Œéå¸¸æ–¹ä¾¿ã€‚\n",
      "\n",
      "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ecapulate model response function\n",
    "def get_response(messages):\n",
    "    response = dashscope.Generation.call(\n",
    "        model = 'deepseek-r1',\n",
    "        messages=messages,\n",
    "        result_format='message' # return full message object\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# test the function\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant \"},\n",
    "    {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œä½ æ˜¯ä»€ä¹ˆå¤§æ¨¡å‹ï¼Ÿ\"}\n",
    "]\n",
    "\n",
    "response = get_response(messages)\n",
    "print(response.output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb0e0e",
   "metadata": {},
   "source": [
    "## 6 Searching Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b7186a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: typing_extensions\n",
      "Version: 4.15.0\n",
      "Summary: Backported and Experimental Type Hints for Python 3.9+\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \"Guido van Rossum, Jukka Lehtosalo, Åukasz Langa, Michael Lee\" <levkivskyi@gmail.com>\n",
      "License: \n",
      "Location: e:\\Python\\python3.12\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: aiosignal, anyio, formulaic, openai, pydantic, pydantic_core, typing-inspection\n",
      "---\n",
      "Name: openai\n",
      "Version: 2.14.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: e:\\Python\\python3.12\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# %pip install -U \"typing_extensions>=4.12.2\" \"openai>=1.0.0\"\n",
    "# !pip install openai\n",
    "# !pip show typing_extensions openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05083de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-94b8b730-a050-43a5-94f9-4eba05e72507\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null,\"message\":{\"content\":\"Hello! The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays in six games (4-2) to claim their seventh championship in franchise history. The series was played at a neutral siteâ€”Globe Life Field in Arlington, Texasâ€”due to the pandemic-related adjustments that year.\",\"refusal\":null,\"role\":\"assistant\",\"annotations\":null,\"audio\":null,\"function_call\":null,\"tool_calls\":null}}],\"created\":1766394292,\"model\":\"qwen-plus\",\"object\":\"chat.completion\",\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":67,\"prompt_tokens\":33,\"total_tokens\":100,\"completion_tokens_details\":null,\"prompt_tokens_details\":{\"audio_tokens\":null,\"cached_tokens\":0}}}\n"
     ]
    }
   ],
   "source": [
    "# api_key = os.environ.get('DASHSCOPE_API_KEY')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key =\"sk-16f2c80d9d3e4d7d9cc2f6b43f22dfbd\",  # å¡«å†™ä½ çš„DashScope API Key\n",
    "    # å¡«å†™DashScopeæœåŠ¡çš„base_url\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  \n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}\n",
    "    ],\n",
    "    extra_body={\n",
    "        \"enable_search\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(completion.model_dump_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
